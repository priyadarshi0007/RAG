from dotenv import load_dotenv
import google.generativeai as genai
import os

def generate_gemini_response(promt):
    """
    Generates a response using the google gemini model.

    Args:
      prompt: The input promt for the model.

    Returns:
       The text response generated by gemini model.
    """
    load_dotenv()
    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
    my_config= genai.types.GenerationConfig(temperature=0,top_k=0,top_p=0)
    model=genai.GenerativeModel('gemini-pro', generation_config= my_config)
    answer=model.generate_content(promt)
    return answer.text

def generate_response_with_gemini(prompt, temperature=None, top_k=None, top_p=None):
    """
    Generates a response using the Google Gemini model with customizable configuration.

    Args:
      prompt (str): The input text prompt for the model.
      temperature (float, optional): Controls the randomness of the model's output.
                                      A higher value like 0.8 makes output more random, while 0.2 makes it more focused.
                                      Default is None, which uses the default value of 0.7.
      top_k (int, optional): The number of highest probability vocabulary tokens to consider for each step.
                             Default is None, which uses the default value of 40.
      top_p (float, optional): Controls the cumulative probability for token selection. A value of 0.9 means the model
                               will consider tokens that cumulatively make up 90% of the probability distribution.
                               Default is None, which uses the default value of 0.9.

    Returns:
       str: The text response generated by the Gemini model.
    """
    # Load environment variables
    load_dotenv()
    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
    
    # Dynamically create the default config if no values are provided
    # Default values are 0.7 for temperature, 40 for top_k, and 0.9 for top_p
    config_values = {
        "temperature": temperature if temperature is not None else 0.7,
        "top_k": top_k if top_k is not None else 40,
        "top_p": top_p if top_p is not None else 0.9,
    }
    
    # Create the generation configuration with the values
    generation_config = genai.types.GenerationConfig(**config_values)
    
    # Load the model
    model = genai.GenerativeModel('gemini-pro', generation_config=generation_config)
    
    # Generate the response using the model and configuration
    answer = model.generate_content(prompt)
    return answer.text